{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run IMPORT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clumping, COJO, PAINTOR, VEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare files for Clumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_pickle('data/healthspan.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojodf = summary.reset_index()\n",
    "cojodf['TEST'] = 'ADD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojodf = summary.rename(columns={'P':'P_notcorrected'})\n",
    "cojodf['TEST'] = 'ADD'\n",
    "\n",
    "lambda_gc = 1.0532\n",
    "split = np.array_split(summary['STAT']/np.sqrt(lambda_gc),n_jobs)\n",
    "concat = pd.concat(multiproc_pbar(parallel_p, [split], [True]))\n",
    "\n",
    "cojodf['P'] = concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojodir = 'healthspan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "for chrom in pbar(cojodf['Chromosome'].unique()):\n",
    "    chrslice = cojodf[cojodf['Chromosome']==chrom]\n",
    "    chrslice = chrslice.drop_duplicates(subset=['Marker'], keep=False)\n",
    "    chrslice.to_csv(\n",
    "        '%s/chr%d.assoc.linear.gz' % (cojodir,int(chrom)),\n",
    "               sep='\\t', index=False, compression='gzip',\n",
    "              columns=['Chromosome','Marker','Position','eff_allele','TEST','PhenoCount','Slope','STAT','P'],\n",
    "             header=['CHR','SNP','BP','A1','TEST','NMISS','BETA','STAT','P'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000g for PAINTOR ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c {1..22}; do\n",
    "    wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr$c.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz;\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in {1..22}; do\n",
    "    zgrep -v '^#' ref/ALL.chr$c.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | cut -f 3 | sort | uniq -d > ref/chr$c.dups;\n",
    "    echo $c;\n",
    "    wc -l ref/chr$c.dups;\n",
    "    plink --vcf ref/ALL.chr$c.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz --exclude ref/chr$c.dups --keep EUR.txt --make-bed --out ref/chr$c;\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojodir=/data/cojo/andersen_list_1000g_2\n",
    "refdir=/data/1000g/ref\n",
    "parallel --joblog clumping.log --eta plink --bfile {.} --keep-allele-order \\\n",
    "--clump $cojodir/{/.}.assoc.linear.gz --clump-p1 5e-8 --maf 0.002 \\\n",
    "--clump-p2 5e-8 --clump-r2 0.1 --clump-range /data/UKBB/sup/glist-hg19 \\\n",
    "--out $cojodir/{/.} ::: $refdir/chr*bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepares files for PAINTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdir='/data/10KREFS/10kref_imp_v2'\n",
    "paintordir = '/data/paintor/paintor_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(paintordir)\n",
    "annotation_files = glob('/data/soft/dist/Functional_Annotations/GeneElements_Gencode/*')\n",
    "np.savetxt('/data/files/paintor_annotation_files', annotation_files, fmt='%s')\n",
    "\n",
    "def parallel(f):\n",
    "    name = basename(f).split('.')[0]\n",
    "\n",
    "    df = pd.read_csv('%s/%s.assoc.linear.gz' % (cojodir,name), delim_whitespace=True, dtype=str,\n",
    "                     engine='c', memory_map=True, usecols=['SNP','BP','STAT','CHR'], index_col='SNP')\n",
    "    clumps = pd.read_csv(f, delim_whitespace=True, index_col='SNP', usecols=['SNP','SP2','CHR','BP'],\n",
    "                         na_values=['NONE'])\n",
    "    for locus, sp2 in clumps.iterrows():\n",
    "    #         if chromosome==6 and (24e6<position<35e6):\n",
    "    #             continue\n",
    "        snplist = []\n",
    "        if sp2.notnull().SP2:\n",
    "            snplist += map(lambda x: x.split('(')[0], sp2.SP2.split(','))\n",
    "        snplist += [locus]\n",
    "        data = df.ix[snplist]\n",
    "        if len(data)<2:\n",
    "            print data\n",
    "            continue\n",
    "        data['index'] = data.index\n",
    "        data['chr'] = 'chr'+data.CHR\n",
    "        data.rename(columns={'BP':'pos', 'STAT':'ZSCORE', 'index':'rsid'}, inplace=True)\n",
    "#         print data\n",
    "        data.to_csv('%s/%s'%(paintordir,locus), sep=' ', index=False)\n",
    "        data.to_csv('%s/%s.snplist'%(paintordir,locus), sep=' ', index=False, columns=['rsid'], header=False)\n",
    "        ldcmd = ['plink','--bfile','%s/%s'%(refdir,name),'--keep-allele-order','--extract',\n",
    "                 '%s/%s.snplist'%(paintordir,locus),'--r','square','spaces','--out','%s/%s'%(paintordir,locus)]\n",
    "        print(' '.join(ldcmd))\n",
    "        subprocess.check_call(ldcmd)\n",
    "\n",
    "        ld = pd.read_csv('%s/%s.ld'%(paintordir,locus), sep=' ', na_values=['nan'], header=None)\n",
    "        ld.fillna(0).to_csv('%s/%s.ld'%(paintordir,locus), sep=' ', header=False, index=False)\n",
    "        pd.DataFrame(np.ones(len(data)).astype(int), columns=['empty']).to_csv(\n",
    "            '%s/%s.annotations'%(paintordir,locus), index=False)\n",
    "\n",
    "flst = glob('%s/*.clumped'%cojodir)\n",
    "for f in flst:\n",
    "    print f\n",
    "    parallel(f)\n",
    "# multiproc_pbar(parallel, [flst], [True]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = [f.split('.')[0].split('/')[-1] for f in glob('%s/*.ld'%paintordir)]\n",
    "np.savetxt('%s/paintor.filelist'%paintordir, input_file, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runs PAINTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [basename(elem) for elem in np.loadtxt('/data/files/paintor_annotation_files',\n",
    "                                                     dtype=str)]\n",
    "\n",
    "def parallel(annotation):\n",
    "    ancmd = ['PAINTOR','-input','%s/paintor.filelist'%paintordir,'-Zhead','ZSCORE','-LDname','ld',\n",
    "             '-in','%s/'%paintordir,'-out','%s/'%paintordir,\n",
    "#              '-enumerate','2',\n",
    "             '-RESname','%s_results'%annotation,\n",
    "             '-Gname','%s/Enrich.%s'%(paintordir,annotation),\n",
    "             '-Lname','%s/BF.%s'%(paintordir,annotation)]\n",
    "    print ' '.join(ancmd)\n",
    "    subprocess.check_call(ancmd)\n",
    "\n",
    "parallel('empty')\n",
    "# multiproc_pbar(parallel, [annotations], [True]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_pickle('/data/files/500k_maf001_info09_snpdata.pkl').set_index('newindex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flst = glob('%s/*.empty_results'%paintordir)\n",
    "mass = []\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for f in pbar(flst):\n",
    "\n",
    "    inp = pd.read_csv(f, sep=' ')\n",
    "#     inp['rsid'] = inpt.loc[inp.rsid,'RSID'].values\n",
    "    inp['chr'] = inp['chr'].apply(lambda x: x[3:])\n",
    "    inp.drop(['ZSCORE'], axis=1, inplace=True)\n",
    "    inp['locus_id'] = splitext(basename(f))[0]\n",
    "    threshold = 0.99*inp.Posterior_Prob.sum()\n",
    "    inp.sort_values('Posterior_Prob', ascending=False, inplace=True)\n",
    "#     print inp.values[0,2]\n",
    "    cumsum = inp.Posterior_Prob.cumsum()\n",
    "    for i, elem in enumerate(cumsum.values):\n",
    "        if cumsum.values[i]<threshold and cumsum.values[i+1] >threshold:\n",
    "            new_threshold = cumsum.values[i+1]\n",
    "            break\n",
    "    ix = cumsum.index[:i+2]\n",
    "    inp['above_threshold'] = False\n",
    "    inp.loc[ix,'above_threshold'] = True\n",
    "    mass.append(inp)\n",
    "\n",
    "df = pd.concat(mass, ignore_index=False).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.concat({chrom: pd.read_csv('/data/UKBB/imputed/ukb_mfi_chr%s_v3.txt'%chrom,\n",
    "                   sep='\\t', header=None,\n",
    "                 usecols=(1,2,3,4)) for chrom in range(1,23)}).reset_index().drop(['level_1'], axis=1)\n",
    "\n",
    "ids['newindex'] = ids['level_0'].astype(str)+':'+ids[2].astype(str)+'_'+ids[3]+'_'+ids[4]\n",
    "# bims = pd.concat([pd.read_csv(f, sep='\\t', header=None) for f in glob('/data/10KREFS/10kref_imp_v2/chr*bim')])\n",
    "ids[[1,'newindex']].set_index('newindex')[1].to_csv('/data/files/newindex2rsid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv('/data/files/newindex2rsid.csv', squeeze=True, header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsid'] = ids[df['rsid'].values].values\n",
    "df['locus_id'] = ids[df['locus_id'].values].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['above_threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('%s/paintor.tsv'%paintordir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilog_dir = join(paintordir,'1000g_ld')\n",
    "mkdir(kilog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom, group in df[df['above_threshold']].groupby('CHR'):\n",
    "    bim1kg = pd.read_csv('/data/1000g/ref/chr%02d.bim'%chrom, sep='\\t', header=None)\n",
    "    snps = np.intersect1d(group['rsid'].values, bim1kg[1].values)\n",
    "#     print(len(group['rsid'].values),len(snps))\n",
    "    ancmd = ('plink --bfile /data/1000g/ref/chr%02d --r2 inter-chr --ld-window-r2 0.8 --ld-snps '\n",
    "          '%s --out %s/chr%02d'%(chrom, ', '.join(snps), kilog_dir, chrom)).split(' ')\n",
    "    subprocess.check_call(ancmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp1kg = pd.concat([pd.read_csv(f,\n",
    "                    delim_whitespace=True) for f in glob('/data/paintor/paintor_test/1000g_ld/chr*.ld')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp1kg.to_csv('/data/tables/suptable5b.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veplist = np.unique(np.hstack((df.loc[df['above_threshold'],'rsid'].values,\n",
    "                               snp1kg['SNP_B'].values)))\n",
    "\n",
    "veplist = veplist[[elem[:2]=='rs' for elem in veplist]]\n",
    "\n",
    "np.savetxt('%s/paintor4vep.txt'%paintordir, veplist, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['above_threshold'],'rsid'].to_csv('%s/paintor4vep.txt'%paintordir, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('%s/paintor.tsv'%paintordir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsidcol = df.pop('rsid')\n",
    "df['rsid'] = ids.set_index('newindex').loc[rsidcol.values,'rsid'].values\n",
    "df[df['locus_id'].isin(['2:202204741_T_C','6:396321_C_T','6:161013013_T_C','9:22102165_C_T',\n",
    "                        '10:114754071_T_C'])&df['above_threshold']].reset_index().drop(['index'], axis=1).to_csv(\n",
    "    'paintor/paintor.tsv', sep='\\t', columns=['chr','pos','rsid','locus_id','Posterior_Prob'], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('paintor_1000g/paintor.tsv', sep='\\t')\n",
    "a['rsid'].to_csv('paintor/paintor4vep.txt', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make COJO on calls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('GWAS-2/cox/pheno5/ukb_cal_chr22_v2.pkl')[[0.0,1.0,2.0,3.0]].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_calls_to_ma(phenoname):\n",
    "    inp = pd.concat([pd.read_pickle('GWAS-2/cox/%s/ukb_cal_chr%s_v2.pkl'%(phenoname,f)) for f in range(1,23)])\n",
    "    inp = pd.concat([inp, pd.DataFrame([elem for elem in inp.reset_index()['index'].apply(lambda x: x.split('_'))],\n",
    "                 columns=['chr','rsid','0','pos','a','b'], index=inp.index)], axis=1)\n",
    "    Nsamples = inp[[0.0,1.0,2.0]].sum(1).astype(int)\n",
    "    inp['EAF'] = (inp[1.0]+inp[2.0]*2)/(Nsamples*2.)\n",
    "    inp = inp.dropna(subset=['beta','sigma','EAF'], how='any')\n",
    "    inp['PhenoCount'] = Nsamples\n",
    "    inp['p'] = (inp['beta']/inp['sigma']).apply(pval)\n",
    "\n",
    "    try:\n",
    "        mkdir(join('/home//data/GWAS-2/cojo',phenoname))\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    pbar = ProgressBar()\n",
    "    for chrom in pbar(inp['chr'].unique()):\n",
    "        inp[inp['chr']==chrom].to_csv('/home//data/GWAS-2/cojo/%s/ukb_cal_chr%s_v2.ma'%(phenoname,chrom),\n",
    "                                                       index=False, sep=' ',\n",
    "            columns=['rsid','a','b','EAF','beta','sigma','p','PhenoCount'],\n",
    "            header=['SNP','A1','A2','freq','b','se','p','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phenoi in range(1,11):\n",
    "    phenoname = save_calls_to_ma('pheno%s'%phenoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojo1 = pd.concat([pd.read_csv(f, sep='\\t') for f in glob(\n",
    "    '/home//data/GWAS-2/cojo/andersen_newfam/ukb_cal_chr*.jma.cojo')])\n",
    "cojo2 = pd.concat([pd.read_csv(f, sep='\\t') for f in glob(\n",
    "    '/home//data/GWAS-2/cojo/andersen_noC44/ukb_cal_chr*.jma.cojo')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojo1.sort_values(['Chr','bp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojo2.sort_values(['Chr','bp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make COJO on imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endslice = pd.read_pickle('/home//data/GWAS-2/gwas/cardiometabolic.pkl').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endslice['EAF'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexslice = bigdf[bigdf['emaf']>0.001].index\n",
    "endslice = summary.loc[indexslice,:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "for chrom in pbar(endslice['Chromosome'].unique()):\n",
    "    endslice[endslice['Chromosome']==chrom].to_csv(\n",
    "        '/home//data/GWAS-2/cojo/cardiometabolic/chr%02d.ma'%int(chrom), index=False, sep=' ',\n",
    "        columns=['newindex','eff_allele','ref_allele','EAF','Slope','SESlope','P','PhenoCount'],\n",
    "        header=['SNP','A1','A2','freq','b','se','p','N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdir=/mnt/tmp/10KREFS/10kref_imp4cojo_v3\n",
    "cojodir=/home//data/GWAS-2/cojo/cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel cp {} {}_original ::: $refdir/*bim\n",
    "\n",
    "for f in $refdir/*bim; do\n",
    "    echo $f;\n",
    "    awk '{print $1\"\\t\"$1\":\"$4\"_\"$5\"_\"$6\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6}' $f > tmp.txt;\n",
    "    mv tmp.txt $f; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel --eta gcta64 --bfile $refdir/{/.} --maf 0.002 --cojo-file {} --cojo-slct --cojo-p 5e-8 --out {.} ::: $cojodir/chr*ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate COJO slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_pickle('data/healthspan.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cojo = pd.concat([pd.read_csv(f, sep='\\t') for f in glob('/home//data/GWAS-2/cojo/andersen_list_v3/chr*.jma.cojo')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workslice = summary.loc[cojo['SNP'],['Chromosome','Marker']]\n",
    "\n",
    "for chrom in workslice['Chromosome'].unique():\n",
    "        print('plink2 --pfile /mnt/10kref/merged/chr%02d --snps %s --export A --out '\n",
    "          '/home//data/GWAS-2/cojo/andersen_list_v3/chr%02d' % (int(chrom),\n",
    "                    ' '.join(workslice.loc[workslice['Chromosome']==chrom,'Marker'].values),int(chrom)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {
   "height": "278px",
   "width": "257px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
